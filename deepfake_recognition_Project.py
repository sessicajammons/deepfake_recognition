# -*- coding: utf-8 -*-
"""deepfake_recognition Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bZhyh3B_GvYTeojNp2H-z76mqFxm-9nf
"""

"""
deepfake_recognition Final Project
CS 555 AI
Spring 2025

Group 2
Members: Simardeep Khinda, Peter Nguyen, Jessica Sammons, Catharine Tew

This code was adapted with the help of Shradhdha Bhalodia's code at
https://www.kaggle.com/code/praveenraj001/deep-fake-image-classification-using-cnn
The dataset used in this code is provided on the Kaggle website:
https://www.kaggle.com/datasets/saurabhbagchi/deepfake-image-detection/data

In this project we use AI model to classify images as fake or real.
This code file loads the dataset, trains,
create a trained model file .keras, then does prediction on individual images.
The results include confusion matrix, accuracy, precision, recall, and F1 score.

"""

"""
this is the folder structure of a kaggle dataset

deepfake-image-detection
	Sample_fake_images
		Sample_fake_images
			fake
				IMG-20240106-WA0009.jpg
				...
	test-20250112T065939Z-001
		test
			fake
				...
			real
				...
	train-20250112T065955Z-001
		train
			fake
				...
			real
				...

"""

# Import Modules
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import glob
import numpy as np
import tensorflow
from PIL import Image
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Commented out IPython magic to ensure Python compatibility.
#Mouting a drive if using Google Colab, etc. "work_dir" in the next Code cell will need to be updated accordingly.
# E.g.)
from google.colab import drive
drive.mount('/content/drive')

# %cd /content/drive/My Drive

"""# Load Data"""

###########################
# Load Data

# Set dataset path (update based on environment)
dataset_path = "/content/drive/My Drive/Colab Notebooks/deepfake-image-detection/train-20250112T065955Z-001/train"

"""
Load image paths and categories from the training dataset, display sample images.
Args:
    dataset_path (str): Path to the dataset folder containing category subfolders.
Returns:
    tuple: (img_paths, categories) where img_paths is a list of image file paths
            and categories is a list of category names.
"""
# List categories (fake & real)
categories = [category for category in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, category))]

# Collect all image paths and sample images for display
img_paths = []
sample_images = []
for category in categories:
    class_path = os.path.join(dataset_path, category)
    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]
    for img in images:
        img_path = os.path.join(class_path, img)
        img_paths.append((img_path, category))  # Store path and category
        if len(sample_images) < 10 and len([s for s, c in sample_images if c == category]) < 5:
            sample_images.append((img_path, category))  # Limit to 5 per category

# Display sample images
fig, axes = plt.subplots(2, 5, figsize=(12, 6))
for i, (img_path, label) in enumerate(sample_images):
    img = load_img(img_path)
    ax = axes[i // 5, i % 5]
    ax.imshow(img)
    ax.set_title(label)
    ax.axis("off")
plt.show()

print(f"Found {len(img_paths)} images in {len(categories)} categories.")
!ls "/content/drive/My Drive/Colab Notebooks/deepfake-image-detection"

"""# Train CNN Model"""

###########################
# Train CNN Model

"""
Train a CNN model using the provided image paths and categories.
Args:
    img_paths (list): List of tuples (image_path, category).
    categories (list): List of category names.
Returns:
    model: Trained Keras model.
"""

IMG_SIZE = (128, 128)
BATCH_SIZE = 32

# Function to load and preprocess images
def load_and_preprocess_image(img_path):
    img = load_img(img_path, target_size=IMG_SIZE)
    img_array = img_to_array(img) / 255.0
    return img_array

# Load all images and labels
image_data = []
labels = []
label_map = {category: idx for idx, category in enumerate(categories)}
for img_path, category in img_paths:
    image_data.append(load_and_preprocess_image(img_path))
    labels.append(label_map[category])

# Convert to numpy arrays
image_data = np.array(image_data)
labels = np.array(labels)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)

print(f"Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}")

# Define augmentation parameters
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Generate augmented images
augmented_images = datagen.flow(X_train[:5], batch_size=5)
fig, axes = plt.subplots(1, 5, figsize=(12, 4))
for i, img in enumerate(augmented_images):
    if i >= 1:
        break
    for j in range(5):
        axes[j].imshow(img[j])
        axes[j].axis("off")
plt.show()

# Build CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation="relu", input_shape=(128, 128, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation="relu"),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation="relu"),
    Dropout(0.5),
    Dense(len(categories), activation="softmax")
])

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model.summary()

history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
                    validation_data=(X_val, y_val),
                    epochs=10,
                    verbose=1)

# Plot Accuracy and Loss Curves
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.legend()
plt.title("Accuracy")
plt.subplot(1, 2, 2)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.legend()
plt.title("Loss")
plt.show()

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

# Save the trained model
model.save('/content/drive/My Drive/Colab Notebooks/deepfake-image-detection/model.keras')

"""# Predictions & Results"""

###########################
# Predictions and Results

# Get prediction of 1 image passed as link to file in google drive
def raw_predict(model, test_img_path):
    """
    Predict the class of a single test image.
    Args:
        model: Trained Keras model.
        test_img_path (str): Path to the test image.
    """
    input_img = load_img(test_img_path, target_size=(128, 128))
    input_array = img_to_array(input_img)
    input_array = np.expand_dims(input_array, axis=0)
    input_array = input_array / 255.0

    predictions = model.predict(input_array)
    print("Raw predictions (probabilities for each class):", predictions)

    predicted_class_idx = np.argmax(predictions, axis=-1)
    print(f"Predicted class index: {predicted_class_idx}")

    class_labels = ['fake', 'real']
    # Check if predicted_class_idx[0] is within the valid range
    if 0 <= predicted_class_idx[0] < len(class_labels):
        predicted_class_name = class_labels[predicted_class_idx[0]]
        print(f"Predicted class name: {predicted_class_name}")
    else:
        print(f"Warning: Predicted class index {predicted_class_idx[0]} is out of range.")
        print(f"Valid class indices are: 0 to {len(class_labels) - 1}")

    #Display that image
    img = load_img(test_img_path)
    plt.imshow(img)
    plt.axis("off")
    #plt.title("Image")
    plt.show()
#def evaluate_folders(model, folders_dict, class_labels=['fake', 'real']):

# Example test image path (update to a valid image from your dataset)
test_img_path = "/content/drive/My Drive/Colab Notebooks/deepfake-image-detection/test-20250112T065939Z-001/test/fake/123.jpg"

raw_predict(model, test_img_path)



#format [fake, real]

class_labels = ['fake', 'real']

folder_label_map = {
    "/content/drive/My Drive/Colab Notebooks/deepfake-image-detection/test-20250112T065939Z-001/test/fake": 0,
    "/content/drive/My Drive/Colab Notebooks/deepfake-image-detection/test-20250112T065939Z-001/test/real": 1
}

"""
Evaluate the model on multiple folders of images and print aggregate results.

Args:
    model: Trained Keras model.
    folders_dict (dict): Dictionary mapping category labels to folder paths.
                          Example: {'fake': '/path/to/fake_images', 'real': '/path/to/real_images'}
    class_labels (list): List of class label strings, in the order corresponding to model outputs.
"""
IMG_SIZE = (128, 128)
true_labels = []
y_pred = []

#label_map = {label: idx for idx, label in enumerate(class_labels)}

for label, folder_path in folder_label_map.items():
    # The issue was here. You were assigning the value (0 or 1) to true_label
    # instead of the actual path.
    true_label = folder_label_map[label]

    # We need to use the key 'label' which contains the path as folder_path
    for img_file in os.listdir(label): # Using 'label' instead of 'folder_path'
        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
            img_path = os.path.join(label, img_file) # Using 'label' instead of 'folder_path'
            try:
                img = load_img(img_path, target_size=IMG_SIZE)
                img_array = img_to_array(img) / 255.0
                input_array = np.expand_dims(img_array, axis=0)
                predictions = model.predict(input_array, verbose=0)
                predicted_class_idx = np.argmax(predictions, axis=-1)[0]
                true_labels.append(true_label)
                y_pred.append(predicted_class_idx)
            except Exception as e:
                print(f"Error with image {img_path}: {e}")

# Evaluation metrics
acc = accuracy_score(true_labels, y_pred)
prec = precision_score(true_labels, y_pred, average='weighted', zero_division=0)
rec = recall_score(true_labels, y_pred, average='weighted', zero_division=0)
f1 = f1_score(true_labels, y_pred, average='weighted', zero_division=0)

print(f"\nEvaluation Results on {len(true_labels)} images:")
print(f"Accuracy:  {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1 Score:  {f1:.4f}")

# Confusion matrix
cm = confusion_matrix(true_labels, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

print("\nðŸ“Š Classification Report:")
print(classification_report(true_labels, y_pred, target_names=class_labels))